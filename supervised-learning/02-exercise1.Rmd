---
title: "Big Data Analysis"
subtitle: "ML Basics and CART"
author: "Christoph Kern"
output: html_notebook
---

## Setup

```{r}
library(rpart)
library(partykit)
library(caret)
library(pROC)
```

In this exercise, we use a reduced version of the Bank for the Accounts of Companies Harmonized (BACH) data set. "The Bank for the Accounts of Companies Harmonized (BACH) is a free-of-charge database containing the aggregated accounting data of non-financial incorporated enterprises for, so far, 11 European countries." More information about the BACH data can be found here:

https://www.bach.banque-france.fr/?lang=en

```{r}
load("BACH.Rda")
```

## Data preparation

As a starting point, we begin with summarizing all variables to get a first impression of the data.

```{r}
summary(bach)
```

Our machine learning task is to predict whether a corporation experiences a net loss in the year 2015. For this setting, we first compute a binary variable which indicates a loss with "loss" and returns "no_loss" otherwise, based on the variable `bach$net_profit_or_loss`.

```{r}
bach$D_loss <- ifelse(bach$net_profit_or_loss < 0, "loss", "no_loss")
bach$D_loss <- as.factor(bach$D_loss)
summary(bach$D_loss)
```

Then we split the data set into a training and test part. Since the data is structured by time, we want to use the year 2015 for the test set and all remaining years for training.

```{r}
bach_test <- bach[bach$year == "2015",]
bach_train <- bach[bach$year != "2015",]
```

## CART

### Grow and prune tree

In order to build a classification tree with the training data, the `rpart()` function can be used. As the outcome variable, we plug in the new variable we created earlier. If this variable is of class factor, `rpart` adapts to this format and grows a classification tree (instead of a regression tree). Use all variables besides `net_profit_or_loss` and `return_on_equity` as predictors, e.g. via `outcome ~ . - net_profit_or_loss - return_on_equity`.

```{r}
set.seed(6342)
f_tree <- rpart(D_loss ~ . - net_profit_or_loss - return_on_equity, 
                data = bach_train, 
                cp = 0.001)
f_tree
```

Next, we want to investigate the Cross-Validation results to find the optimal subtree based on the `rpart` object.

```{r}
printcp(f_tree)
plotcp(f_tree)
```

For pruning, we need the `cp` value of the best subtree. In this code block we prepare tree pruning, e.g. according to the 1-Standard Error rule.

```{r}
minx <- which.min(f_tree$cptable[,"xerror"])
minxse <- f_tree$cptable[minx,"xerror"] + f_tree$cptable[minx,"xstd"]
minse <- which.min(abs(f_tree$cptable[1:minx,"xerror"] - minxse))
mincp <- f_tree$cptable[minse,"CP"]
mincp
```

Now prune the classification tree.

```{r}
p_tree <- prune(f_tree, cp = mincp)
p_tree
```

### Variable Importance and Plot

We can inspect the tree results by plotting the pruned classification tree. However, be prepared that also pruned trees can be quite large.

```{r}
prty_tree <- as.party(p_tree)
plot(prty_tree, gp = gpar(fontsize = 6))
```

The `varImp()` function is useful for listing the importance of each predictor variable for reducing node impurity.

```{r}
varImp(p_tree)
```

## Prediction

For evaluating performance, we predict the outcome in the test set in two formats. We want to use `predict()` for predicting class membership and also for computing predicted probabilities. Therefore, two prediction objects are generated.

```{r}
y_class <- predict(p_tree, newdata = bach_test, type = "class")
y_prob <- predict(p_tree, newdata = bach_test, type = "prob")
head(y_prob)
```

Given predicted class membership, we can use the function `confusionMatrix()` for evaluating our classification model.

```{r}
confusionMatrix(y_class, bach_test$D_loss, mode = "everything", positive = "loss")
```

Additionally, ROC curves are helpful for evaluating prediction performance with categorical outcomes. Here we could (e.g.) use the `pROC` package, which has a function called `roc()`.

```{r}
y_roc <- roc(bach_test$D_loss, y_prob[, 1])
```

On this basis, we can print and plot the resulting roc object.

```{r}
y_roc
ggroc(y_roc) + 
    geom_segment(aes(x = 1, xend = 0, y = 0, yend = 1), color = "grey")
```

Extra task: Try to calculate precision at top 100, i.e. the expected precision when classifying the 100 test observations with the highest risk scores as `loss`. For this, we need to create a new prediction vector. The function `order()` might be helpful here.

```{r}
yp <- data.frame(y_prob[, 1], bach_test$D_loss)
yp <- yp[order(-yp[, 1]), ]
yp$y_top100 <- "no_loss"
yp[1:100, ]$y_top100 <- "loss"
```

Finally, compute the `precision()` given the new predicted classes.

```{r}
precision(as.factor(yp$y_top100), yp$bach_test.D_loss, relevant = "loss")
```
